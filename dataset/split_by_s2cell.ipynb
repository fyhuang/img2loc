{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas\n",
    "import tqdm\n",
    "\n",
    "from mlutil import label_mapping, s2cell_mapping\n",
    "\n",
    "s2mapping = s2cell_mapping.S2CellMapping.from_label_mapping(\n",
    "    label_mapping.LabelMapping.read_csv(Path.home() / \"datasets/img2loc/s2cell_930_ml.csv\")\n",
    ")\n",
    "\n",
    "def annotate_s2_classes(img_root, df):\n",
    "    # Assign each row a list of classes\n",
    "    def class_list_str(row):\n",
    "        one_hot = s2mapping.lat_lng_to_multihot_list(row.latitude, row.longitude)\n",
    "        class_numbers = [i for i, v in enumerate(one_hot) if v]\n",
    "        class_numbers.sort()\n",
    "        return \",\".join(str(i) for i in class_numbers)\n",
    "\n",
    "    # Make sure every img_path is valid (otherwise class index doesn't make sense)\n",
    "    exists = []\n",
    "    for img_path in tqdm.tqdm(df.img_path, desc=\"Checking images\"):\n",
    "        exists.append((img_root / img_path).exists())\n",
    "    df[\"img_exists\"] = exists\n",
    "    df = df[df.img_exists].copy()\n",
    "\n",
    "    s2_classes = []\n",
    "    for row in tqdm.tqdm(df.itertuples(), total=len(df), desc=\"Annotating s2_classes\"):\n",
    "        s2_classes.append(class_list_str(row))\n",
    "    df[\"s2_classes\"] = s2_classes\n",
    "\n",
    "    return df\n",
    "\n",
    "def annotate_classindex(df):\n",
    "    # Shuffle and pick the first N of each class\n",
    "    df = df.sample(frac=1, ignore_index=True)\n",
    "\n",
    "    s2_classes_count = collections.Counter() # how many of each classlist have we seen already\n",
    "    sameclass_index = []\n",
    "    for row in tqdm.tqdm(df.itertuples(), total=len(df), desc=\"Class index\"):\n",
    "        sameclass_index.append(s2_classes_count[row.s2_classes])\n",
    "        s2_classes_count[row.s2_classes] += 1\n",
    "    df[\"sameclass_index\"] = sameclass_index\n",
    "\n",
    "    return df\n",
    "\n",
    "def assign_split(df, n):\n",
    "    # Pick the first N sameclass_index as the validation set\n",
    "    split = []\n",
    "    for row in tqdm.tqdm(df.itertuples()):\n",
    "        split.append(\"val\" if row.sameclass_index < n else \"train\")\n",
    "    df[\"split\"] = split\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 773879/773879 [00:53<00:00, 14479.25it/s]\n",
      "100%|██████████| 773879/773879 [00:06<00:00, 119713.00it/s]\n",
      "100%|██████████| 773879/773879 [00:02<00:00, 312361.64it/s]\n",
      "773879it [00:02, 329910.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6970, 766909)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n=8 for im2gps combined v2\n",
    "df = pandas.read_pickle(Path.home() / \"LocalProjects/datasets/im2gps/outputs/clustered/im2gps_1_filtered.pkl\")\n",
    "df = annotate_s2_classes(df)\n",
    "df = annotate_classindex(Path.home() / \"LocalProjects/datasets/im2gps/outputs/img\", df)\n",
    "df.to_pickle(Path.home() / \"LocalProjects/datasets/im2gps/outputs/clustered/im2gps_2_classindex.pkl\")\n",
    "shuffled = assign_split(df, 8)\n",
    "shuffled.to_pickle(Path.home() / \"LocalProjects/datasets/im2gps/outputs/clustered/im2gps_3_split.pkl\")\n",
    "\n",
    "(shuffled[\"split\"] == \"val\").sum(), (shuffled[\"split\"] == \"train\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking images: 100%|██████████| 203572/203572 [00:01<00:00, 138465.96it/s]\n",
      "Annotating s2_classes: 100%|██████████| 40033/40033 [00:02<00:00, 15695.86it/s]\n",
      "Class index: 100%|██████████| 40033/40033 [00:00<00:00, 555711.90it/s]\n",
      "40033it [00:00, 622340.48it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1527, 38506)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n=2 for world1 sv\n",
    "df = pandas.read_pickle(Path.home() / \"LocalProjects/datasets/img2loc/outputs/world1/s3_parameterized.pkl\")\n",
    "df = annotate_s2_classes(Path.home() / \"LocalProjects/datasets/img2loc/outputs/world1/img\", df)\n",
    "df = annotate_classindex(df)\n",
    "shuffled = assign_split(df, 2)\n",
    "shuffled.to_pickle(Path.home() / \"LocalProjects/datasets/img2loc/outputs/world1/s4_split.pkl\")\n",
    "\n",
    "(shuffled[\"split\"] == \"val\").sum(), (shuffled[\"split\"] == \"train\").sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
