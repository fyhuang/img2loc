{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiny model, 2 class\n",
    "\n",
    "## Using pytorch lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "import torchmetrics\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA A10'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 128\n",
      "torch.Size([128, 3, 640, 640]) torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "%run datasets.ipynb\n",
    "\n",
    "import webdataset as wds\n",
    "\n",
    "# training set has ~5k samples\n",
    "BATCH_SIZE = auto_batch_size()\n",
    "print(\"Batch size:\", BATCH_SIZE)\n",
    "\n",
    "dataset = wds.WebDataset(str(DATASET_ROOT / \"california_tiny_train.tar\"))\\\n",
    "    .decode(\"torchrgb\").to_tuple(\"jpg\", \"json\")\n",
    "\n",
    "# Transform the labels to either ncal or scal\n",
    "def to_img_label(sample):\n",
    "    img, target = sample\n",
    "    label = 0 if target[\"district\"].lower() in [\"alameda\", \"contra costa\", \"marin\", \"napa\", \"san francisco\", \"san mateo\", \"santa clara\", \"solano\", \"sonoma\", \"sacramento\"] else 1\n",
    "    # TODO: this is where we transform the image\n",
    "    return img, label\n",
    "\n",
    "dataset = dataset.map(to_img_label)\n",
    "dataset = dataset.batched(BATCH_SIZE)\n",
    "\n",
    "# Visualize a few loaded samples\n",
    "dataloader = wds.WebLoader(dataset, batch_size=None, num_workers=0)\n",
    "#dataloader = dataloader.unbatched().shuffle(1000).batched(BATCH_SIZE)\n",
    "\n",
    "for inputs, targets in dataloader:\n",
    "    print(inputs.shape, targets.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a LightningModule for the classifier\n",
    "class NcalScalClassifierMnet3(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        mnet3 = models.mobilenet_v3_large(weights=\"IMAGENET1K_V2\")\n",
    "\n",
    "        self.features = mnet3.features\n",
    "        self.avgpool = mnet3.avgpool\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(mnet3.classifier[0].in_features, 1280),\n",
    "            nn.Hardswish(inplace=True),\n",
    "            nn.Dropout(p=0.2, inplace=True),\n",
    "            nn.Linear(1280, 2),\n",
    "        )\n",
    "\n",
    "        torch.nn.init.xavier_uniform_(self.classifier[0].weight)\n",
    "        torch.nn.init.xavier_uniform_(self.classifier[3].weight)\n",
    "\n",
    "        self.accuracy = torchmetrics.classification.Accuracy(task='multiclass', num_classes=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            x = self.features(x)\n",
    "            x = self.avgpool(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        z = self.forward(x)\n",
    "        self.accuracy(z, y)\n",
    "        self.log('train_acc_step', self.accuracy, prog_bar=True)\n",
    "\n",
    "        loss = nn.CrossEntropyLoss()(z, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        z = self.forward(x)\n",
    "        self.accuracy(z, y)\n",
    "        self.log('test_acc', self.accuracy, on_step=False, on_epoch=True)\n",
    "\n",
    "        test_loss = nn.CrossEntropyLoss()(z, y)\n",
    "        self.log(\"test_loss\", test_loss, prog_bar=True)\n",
    "        return test_loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NcalScalClassifierEn2(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.en2 = models.efficientnet_v2_m(weights=\"IMAGENET1K_V1\")\n",
    "        self.en2.classifier = nn.Sequential(\n",
    "            # Default dropout: s=0.2, m=0.3, l=0.4\n",
    "            nn.Dropout(p=0.3, inplace=True),\n",
    "            nn.Linear(self.en2.classifier[1].in_features, 2),\n",
    "        )\n",
    "\n",
    "        nn.init.xavier_uniform_(self.en2.classifier[1].weight)\n",
    "        nn.init.zeros_(self.en2.classifier[1].bias)\n",
    "\n",
    "        self.accuracy = torchmetrics.classification.Accuracy(task='multiclass', num_classes=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            x = self.en2.features(x)\n",
    "            x = self.en2.avgpool(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "        x = self.en2.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        z = self.forward(x)\n",
    "        self.accuracy(z, y)\n",
    "        self.log('train_acc_step', self.accuracy, prog_bar=True)\n",
    "\n",
    "        loss = nn.CrossEntropyLoss()(z, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        z = self.forward(x)\n",
    "        self.accuracy(z, y)\n",
    "        self.log('test_acc', self.accuracy, on_step=False, on_epoch=True)\n",
    "\n",
    "        test_loss = nn.CrossEntropyLoss()(z, y)\n",
    "        self.log(\"test_loss\", test_loss, prog_bar=True, on_epoch=True)\n",
    "        return test_loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_large-5c1a4163.pth\" to /home/ubuntu/.cache/torch/hub/checkpoints/mobilenet_v3_large-5c1a4163.pth\n",
      "100%|████████████████████████████████████████████████████████████████████████| 21.1M/21.1M [00:00<00:00, 48.1MB/s]\n",
      "You are using a CUDA device ('NVIDIA A10') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: tiny_2class_lightning/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | features   | Sequential         | 3.0 M \n",
      "1 | avgpool    | AdaptiveAvgPool2d  | 0     \n",
      "2 | classifier | Sequential         | 1.2 M \n",
      "3 | accuracy   | MulticlassAccuracy | 0     \n",
      "--------------------------------------------------\n",
      "4.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.2 M     Total params\n",
      "16.818    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: : 40it [00:52,  1.31s/it, v_num=0, train_acc_step=0.769, train_loss=0.542]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: : 40it [00:52,  1.32s/it, v_num=0, train_acc_step=0.769, train_loss=0.542]\n"
     ]
    }
   ],
   "source": [
    "mnet3_model = NcalScalClassifierMnet3()\n",
    "logger = TensorBoardLogger(\"tiny_2class_lightning\")\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=10,\n",
    "    #deterministic=True,\n",
    "    logger=logger,\n",
    "    log_every_n_steps=5,\n",
    ")\n",
    "trainer.fit(model=mnet3_model, train_dataloaders=dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type               | Params\n",
      "------------------------------------------------\n",
      "0 | en2      | EfficientNet       | 52.9 M\n",
      "1 | accuracy | MulticlassAccuracy | 0     \n",
      "------------------------------------------------\n",
      "52.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "52.9 M    Total params\n",
      "211.444   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: : 40it [01:54,  2.86s/it, v_num=0, train_acc_step=0.731, train_loss=0.510]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: : 40it [01:54,  2.87s/it, v_num=0, train_acc_step=0.731, train_loss=0.510]\n"
     ]
    }
   ],
   "source": [
    "en2_model = NcalScalClassifierEn2()\n",
    "logger = TensorBoardLogger(\"tiny_2class_lightning\")\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=10,\n",
    "    #deterministic=True,\n",
    "    logger=logger,\n",
    "    log_every_n_steps=5,\n",
    ")\n",
    "trainer.fit(model=en2_model, train_dataloaders=dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 640, 640]) torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "# Load the test set\n",
    "test_dataset = wds.WebDataset(str(DATASET_ROOT / \"california_tiny_test.tar\"))\\\n",
    "    .decode(\"torchrgb\").to_tuple(\"jpg\", \"json\")\n",
    "test_dataset = test_dataset.map(to_img_label).batched(BATCH_SIZE)\n",
    "test_dataloader = wds.WebLoader(dataset, batch_size=None, num_workers=0)\n",
    "#dataloader = dataloader.unbatched().shuffle(1000).batched(BATCH_SIZE)\n",
    "\n",
    "for inputs, targets in test_dataloader:\n",
    "    print(inputs.shape, targets.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: : 40it [00:47,  1.20s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8000392317771912     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4450194537639618     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8000392317771912    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4450194537639618    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.4450194537639618, 'test_acc': 0.8000392317771912}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnet3_model = NcalScalClassifierMnet3.load_from_checkpoint(\"mnet3_checkpoint_version_0.ckpt\")\n",
    "trainer.test(model=mnet3_model, dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: : 40it [01:41,  2.53s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7335164546966553     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.526933491230011     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7335164546966553    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.526933491230011    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.526933491230011, 'test_acc': 0.7335164546966553}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en2_model = NcalScalClassifierEn2.load_from_checkpoint(\"en2_checkpoint_version_0.ckpt\")\n",
    "trainer.test(model=en2_model, dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_dataloader = wds.WebLoader(test_dataset.map(lambda x, y: x), batch_size=None, num_workers=0)\n",
    "\n",
    "for inputs in predict_dataloader:\n",
    "    print(inputs.shape)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
