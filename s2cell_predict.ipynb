{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1070'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "import torchmetrics\n",
    "import webdataset as wds\n",
    "\n",
    "import label_mapping\n",
    "\n",
    "TORCH_ACCELERATOR = \"cpu\"\n",
    "\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<label_mapping.LabelMapping at 0x7f0b5bc67410>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run datasets.ipynb\n",
    "\n",
    "DATASET_ROOT = Path.home() / \"datasets\" / \"im2gps\" / \"outputs\"\n",
    "\n",
    "# Load the s2cell-annotated dataset\n",
    "annotated_df = pandas.read_pickle(DATASET_ROOT / \"s2cell_2007\" / \"annotated.pkl\")\n",
    "mapping = label_mapping.LabelMapping.read_csv(DATASET_ROOT / \"s2cell_2007\" / \"cells.csv\")\n",
    "\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown device: NVIDIA GeForce GTX 1070\n",
      "Batch size: 1\n",
      "torch.Size([1, 3, 477, 1024]) torch.Size([1]) tensor([1237])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image_id_to_s2cell = {row.id: row.s2cell for row in annotated_df.itertuples()}\n",
    "\n",
    "# total set has ~630k images\n",
    "BATCH_SIZE = auto_batch_size()\n",
    "print(\"Batch size:\", BATCH_SIZE)\n",
    "\n",
    "dataset = wds.WebDataset(\n",
    "        str(DATASET_ROOT / \"wds\" / \"im2gps_2007_{000..038}.tar\"),\n",
    "        shardshuffle=True,\n",
    "    ).decode(\"torchrgb\").to_tuple(\"jpg\", \"json\")\n",
    "\n",
    "# Transform s2cells to labels, skipping examples without s2cell\n",
    "def to_img_label(sample):\n",
    "    img, meta = sample\n",
    "    s2cell = image_id_to_s2cell.get(meta[\"id\"])\n",
    "    if s2cell is None:\n",
    "        raise NotImplementedError(\"Skipping example without s2cell\")\n",
    "    label = mapping.get_label(s2cell)\n",
    "    # TODO: this is where we transform the image\n",
    "    return img, label\n",
    "\n",
    "#dataset = dataset.map(to_img_label, handler=wds.ignore_and_continue)\n",
    "dataset = dataset.map(to_img_label)\n",
    "dataset = dataset.batched(BATCH_SIZE)\n",
    "\n",
    "# Visualize a few loaded samples\n",
    "dataloader = wds.WebLoader(dataset, batch_size=None, num_workers=0)\n",
    "for inputs, targets in dataloader:\n",
    "    print(inputs.shape, targets.shape, targets)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a LightningModule for the classifier\n",
    "class NcalScalClassifierMnet3(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        mnet3 = models.mobilenet_v3_large(weights=\"IMAGENET1K_V2\")\n",
    "\n",
    "        self.features = mnet3.features\n",
    "        self.avgpool = mnet3.avgpool\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(mnet3.classifier[0].in_features, 1280),\n",
    "            nn.Hardswish(inplace=True),\n",
    "            nn.Dropout(p=0.2, inplace=True),\n",
    "            nn.Linear(1280, 2),\n",
    "        )\n",
    "\n",
    "        torch.nn.init.xavier_uniform_(self.classifier[0].weight)\n",
    "        torch.nn.init.xavier_uniform_(self.classifier[3].weight)\n",
    "\n",
    "        self.accuracy = torchmetrics.classification.Accuracy(task='multiclass', num_classes=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            x = self.features(x)\n",
    "            x = self.avgpool(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        z = self.forward(x)\n",
    "        self.accuracy(z, y)\n",
    "        self.log('train_acc_step', self.accuracy, prog_bar=True)\n",
    "\n",
    "        loss = nn.CrossEntropyLoss()(z, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        z = self.forward(x)\n",
    "        self.accuracy(z, y)\n",
    "        self.log('test_acc', self.accuracy, on_step=False, on_epoch=True)\n",
    "\n",
    "        test_loss = nn.CrossEntropyLoss()(z, y)\n",
    "        self.log(\"test_loss\", test_loss, prog_bar=True)\n",
    "        return test_loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=0.001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
