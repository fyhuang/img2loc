{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1070'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "import torchmetrics\n",
    "import webdataset as wds\n",
    "\n",
    "import label_mapping\n",
    "\n",
    "TORCH_ACCELERATOR = \"cpu\"\n",
    "\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<label_mapping.LabelMapping at 0x7f0b48888d50>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run datasets.ipynb\n",
    "\n",
    "DATASET_ROOT = Path.home() / \"datasets\" / \"im2gps\" / \"outputs\"\n",
    "\n",
    "# Load the s2cell-annotated dataset\n",
    "annotated_df = pandas.read_pickle(DATASET_ROOT / \"s2cell_2007\" / \"annotated.pkl\")\n",
    "mapping = label_mapping.LabelMapping.read_csv(DATASET_ROOT / \"s2cell_2007\" / \"cells.csv\")\n",
    "\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown device: NVIDIA GeForce GTX 1070\n",
      "Batch size: 1\n",
      "torch.Size([1, 3, 768, 1024]) torch.Size([1]) tensor([1677])\n",
      "torch.Size([1, 3, 451, 1024]) torch.Size([1]) tensor([1078])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image_id_to_s2cell = {row.id: row.s2cell for row in annotated_df.itertuples()}\n",
    "\n",
    "# total set has ~630k images\n",
    "BATCH_SIZE = auto_batch_size()\n",
    "print(\"Batch size:\", BATCH_SIZE)\n",
    "\n",
    "# Transform s2cells to labels, skipping examples without s2cell\n",
    "def to_img_label(sample):\n",
    "    img, meta = sample\n",
    "    s2cell = image_id_to_s2cell.get(meta[\"id\"])\n",
    "    if s2cell is None:\n",
    "        raise NotImplementedError(\"Skipping example without s2cell\")\n",
    "    label = mapping.get_label(s2cell)\n",
    "    # TODO: this is where we transform the image\n",
    "    return img, label\n",
    "\n",
    "def urls_to_dataset(urls):\n",
    "    return wds.WebDataset(urls, shardshuffle=True)\\\n",
    "        .shuffle(100)\\\n",
    "        .decode(\"torchrgb\").to_tuple(\"jpg\", \"json\")\\\n",
    "        .map(to_img_label, handler=wds.ignore_and_continue)\\\n",
    "        .batched(BATCH_SIZE)\n",
    "\n",
    "train_dataset = urls_to_dataset(str(DATASET_ROOT / \"wds\" / \"im2gps_2007_train_{000..031}.tar\"))\n",
    "val_dataset = urls_to_dataset(str(DATASET_ROOT / \"wds\" / \"im2gps_2007_val_{000..007}.tar\"))\n",
    "\n",
    "# Visualize a few loaded samples\n",
    "train_dataloader = wds.WebLoader(train_dataset, batch_size=None, num_workers=0)\n",
    "for inputs, targets in train_dataloader:\n",
    "    print(inputs.shape, targets.shape, targets)\n",
    "    break\n",
    "\n",
    "val_dataloader = wds.WebLoader(val_dataset, batch_size=None, num_workers=0)\n",
    "for inputs, targets in val_dataloader:\n",
    "    print(inputs.shape, targets.shape, targets)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a LightningModule for the classifier\n",
    "class NcalScalClassifierMnet3(L.LightningModule):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        mnet3 = models.mobilenet_v3_large(weights=\"IMAGENET1K_V2\")\n",
    "\n",
    "        self.features = mnet3.features\n",
    "        self.avgpool = mnet3.avgpool\n",
    "        hidden_size = 2048\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(mnet3.classifier[0].in_features, hidden_size),\n",
    "            nn.Hardswish(inplace=True),\n",
    "            nn.Dropout(p=0.2, inplace=True),\n",
    "            nn.Linear(hidden_size, num_classes), # out is 1776\n",
    "        )\n",
    "\n",
    "        torch.nn.init.xavier_uniform_(self.classifier[0].weight)\n",
    "        torch.nn.init.xavier_uniform_(self.classifier[3].weight)\n",
    "\n",
    "        self.accuracy = torchmetrics.classification.Accuracy(task='multiclass', num_classes=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            x = self.features(x)\n",
    "            x = self.avgpool(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        z = self.forward(x)\n",
    "        loss = nn.CrossEntropyLoss()(z, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "\n",
    "        preds = torch.argmax(z, dim=1)\n",
    "        self.accuracy(preds, y)\n",
    "        self.log('train_acc_step', self.accuracy, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        z = self.forward(x)\n",
    "        val_loss = nn.CrossEntropyLoss()(z, y)\n",
    "        self.log(\"val_loss\", val_loss, prog_bar=True)\n",
    "\n",
    "        preds = torch.argmax(z, dim=1)\n",
    "        self.accuracy(preds, y)\n",
    "        self.log('val_acc', self.accuracy, on_step=False, on_epoch=True)\n",
    "        return val_loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        z = self.forward(x)\n",
    "        test_loss = nn.CrossEntropyLoss()(z, y)\n",
    "        self.log(\"test_loss\", test_loss, prog_bar=True)\n",
    "\n",
    "        preds = torch.argmax(z, dim=1)\n",
    "        self.accuracy(preds, y)\n",
    "        self.log('test_acc', self.accuracy, on_step=False, on_epoch=True)\n",
    "        return test_loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/fyhuang/dev/mlenv/lib/python3.11/site-packages/lightning/pytorch/trainer/setup.py:176: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n",
      "/home/fyhuang/dev/mlenv/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory /home/fyhuang/LocalProjects/img2loc/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | features   | Sequential         | 3.0 M \n",
      "1 | avgpool    | AdaptiveAvgPool2d  | 0     \n",
      "2 | classifier | Sequential         | 5.6 M \n",
      "3 | accuracy   | MulticlassAccuracy | 0     \n",
      "--------------------------------------------------\n",
      "8.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "8.6 M     Total params\n",
      "34.316    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s, train_loss=7.580, train_acc_step=0.000, val_loss=7.550]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s, train_loss=7.580, train_acc_step=0.000, val_loss=7.550]\n"
     ]
    }
   ],
   "source": [
    "mnet3_model = NcalScalClassifierMnet3(num_classes=len(mapping))\n",
    "\n",
    "# Quick test run\n",
    "L.Trainer(\n",
    "    accelerator=TORCH_ACCELERATOR,\n",
    "    fast_dev_run=True,\n",
    ").fit(model=mnet3_model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | features   | Sequential         | 3.0 M \n",
      "1 | avgpool    | AdaptiveAvgPool2d  | 0     \n",
      "2 | classifier | Sequential         | 5.6 M \n",
      "3 | accuracy   | MulticlassAccuracy | 0     \n",
      "--------------------------------------------------\n",
      "8.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "8.6 M     Total params\n",
      "34.316    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: : 1095it [04:32,  4.01it/s, v_num=2, train_loss=5.690, train_acc_step=0.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fyhuang/dev/mlenv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:53: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "# Full training\n",
    "trainer = L.Trainer(\n",
    "    accelerator=TORCH_ACCELERATOR,\n",
    "    callbacks=[\n",
    "        L.pytorch.callbacks.ModelCheckpoint(monitor=\"val_loss\", mode=\"min\"),\n",
    "        L.pytorch.callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\"),\n",
    "    ],\n",
    "    max_epochs=1,\n",
    ")\n",
    "trainer.fit(model=mnet3_model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
