{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotate a (web)dataset with the S2 cell of each example\n",
    "\n",
    "Create a tree of S2 cells adaptively, making sure each cell doesn't have too many/few examples.\n",
    "\n",
    "Apply the S2 cell tree to a webdataset, labeling each example with the smallest S2 cell in the tree that contains the lat/lng of the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import collections\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas\n",
    "import webdataset\n",
    "import s2sphere\n",
    "\n",
    "import tqdm\n",
    "\n",
    "from mlutil import label_mapping\n",
    "\n",
    "MIN_CELL_LEVEL = 6\n",
    "MAX_CELL_LEVEL = 23\n",
    "\n",
    "CELL_MAX_EXAMPLES = 10000\n",
    "CELL_MIN_EXAMPLES = 100\n",
    "\n",
    "TRAIN_DF_PATH = Path.home() / \"datasets\" / \"im2gps\" / \"outputs\" / \"im2gps_2007.pkl\"\n",
    "train_df = pandas.read_pickle(TRAIN_DF_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse the train dataset to build the S2 cell tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 591441/591441 [00:13<00:00, 44250.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# Format: {level: {cell_id: (child_cell_id, ...)}}\n",
    "cells_by_level = collections.defaultdict(lambda: collections.defaultdict(set))\n",
    "\n",
    "# Build the cell_by_id index and initialize cells_by_level\n",
    "for row in tqdm.tqdm(train_df.itertuples(), total=len(train_df.index)):\n",
    "    latlng = s2sphere.LatLng.from_degrees(row.latitude, row.longitude)\n",
    "    s2_cell_id = s2sphere.CellId.from_lat_lng(latlng).parent(MAX_CELL_LEVEL)\n",
    "\n",
    "    parent_cell = s2_cell_id.parent(MIN_CELL_LEVEL)\n",
    "    cells_by_level[parent_cell.level()][parent_cell.id()].add(s2_cell_id.id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Level 1: 0it [00:00, ?it/s]\n",
      "Level 2: 0it [00:00, ?it/s]\n",
      "Level 3: 0it [00:00, ?it/s]\n",
      "Level 4: 0it [00:00, ?it/s]\n",
      "Level 5: 0it [00:00, ?it/s]\n",
      "Level 6:   0%|          | 0/4060 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Level 6: 100%|██████████| 4060/4060 [00:00<00:00, 1573978.58it/s]\n",
      "Level 7: 100%|██████████| 4/4 [00:00<00:00, 28149.69it/s]\n",
      "Level 8: 0it [00:00, ?it/s]\n",
      "Level 9: 0it [00:00, ?it/s]\n",
      "Level 10: 0it [00:00, ?it/s]\n",
      "Level 11: 0it [00:00, ?it/s]\n",
      "Level 12: 0it [00:00, ?it/s]\n",
      "Level 13: 0it [00:00, ?it/s]\n",
      "Level 14: 0it [00:00, ?it/s]\n",
      "Level 15: 0it [00:00, ?it/s]\n",
      "Level 16: 0it [00:00, ?it/s]\n",
      "Level 17: 0it [00:00, ?it/s]\n",
      "Level 18: 0it [00:00, ?it/s]\n",
      "Level 19: 0it [00:00, ?it/s]\n",
      "Level 20: 0it [00:00, ?it/s]\n",
      "Level 21: 0it [00:00, ?it/s]\n",
      "Level 22: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cells = 418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Walk the tree and split cells\n",
    "for level in range(1, MAX_CELL_LEVEL):\n",
    "    celldict = cells_by_level[level]\n",
    "    for cell_id, cellset in tqdm.tqdm(celldict.items(), desc=f\"Level {level}\"):\n",
    "        if len(cellset) <= CELL_MAX_EXAMPLES:\n",
    "            continue\n",
    "\n",
    "        next_level = level+1\n",
    "        for child_id in cellset:\n",
    "            child_cell = s2sphere.CellId(child_id)\n",
    "            next_level_parent = child_cell.parent(next_level)\n",
    "            cells_by_level[next_level][next_level_parent.id()].add(child_id)\n",
    "        cellset.clear()\n",
    "\n",
    "# Flatten the cells_by_level dict and remove cells with too few examples\n",
    "candidate_celldicts = {}\n",
    "for level, celldict in cells_by_level.items():\n",
    "    for cell_id, cellset in celldict.items():\n",
    "        if len(cellset) >= CELL_MIN_EXAMPLES:\n",
    "            candidate_celldicts[cell_id] = cellset\n",
    "\n",
    "print(f\"Number of cells = {len(candidate_celldicts)}\")\n",
    "candidate_tokens = [s2sphere.CellId(cell_id).to_token() for cell_id in sorted(candidate_celldicts.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0099,009b,0717,0d0d,0d11,0d13,0d19,0d1b,0d1f,0d23,0d25,0d2f,0d37,0d3b,0d41,0d43,0d49,0d51,0d61,0d6d,0d71,0d73,0da7,0daf,0ec1,1297,12a1,12a5,12af,12b5,12bb,12c9,12cd,12d5,1325,132b,132f,1335,133b,134b,134d,135b,1449,1459,1495,1499,149b,149d,14a1,14a3,14a9,14bf,14cb,14d3,14e7,14f5,1501,1503,1519,151d,151f,1559,182d,1835,185d,19cd,19dd,1dcd,1e95,1ef7,2a33,2dd3,2e69,3051,3055,30db,30e3,3103,3109,3111,3135,3175,31cd,31db,3397,3401,3403,3405,3443,345d,3469,346f,357d,35b3,35f1,3693,390d,3919,396d,3975,39eb,3a53,3baf,3be7,3e5f,3f8f,3fbd,3fcf,40a5,40ab,40d5,414b,45df,463d,463f,4641,464f,4653,465f,468d,468f,4693,4697,46b5,46dd,46ef,46fd,4709,470b,470f,4715,4717,471f,4741,4761,4763,4765,476d,4771,4773,4777,4779,477b,477d,477f,4781,4783,4785,4787,4789,478d,478f,4791,4795,4797,4799,479b,479d,479f,47a9,47b1,47b3,47b7,47b9,47bd,47bf,47c1,47c3,47c5,47c7,47d9,47dd,47df,47e7,4843,4845,484f,4859,485b,485d,485f,4861,4863,4865,4867,4869,486b,486d,486f,4871,4873,4875,4877,4879,487b,487d,487f,4885,4887,4889,488b,488d,488f,489b,48cd,48d1,48d5,48d7,4cad,4caf,4cb3,4cb5,4cb9,4cc9,4ccb,4ccf,52af,52b3,534f,5351,5353,5371,5401,5485,5487,548f,5491,5493,5495,5497,549b,54af,54bf,54c1,54c7,54eb,56c7,56c9,5d97,6001,6003,6019,671f,6ab1,6ad5,6ad7,6b0d,6b13,6b17,6b91,6b93,6d0d,6d2b,6d39,7953,7955,7c01,7c07,7eab,8085,808d,808f,8095,8097,8099,809b,80c3,80c9,80cb,80cf,80d9,80db,80dd,80e9,8589,858f,85cf,85d1,85d3,8621,8625,8627,863f,8641,8645,864d,864f,865b,865d,8663,86d7,8713,8715,8717,8719,8723,872b,872d,8733,8735,8737,873f,8747,8749,874b,8753,8765,8769,876b,876d,8797,87b3,87b7,87bb,87bf,87c1,87cf,87d9,87e5,87ef,87f7,8805,8807,880f,8811,8817,8819,8823,8825,882b,8831,8833,8835,8839,883b,883d,8841,8849,884b,884d,8859,885f,8861,8865,8869,886d,8871,8889,888f,889b,88c3,88cd,88d1,88d9,88db,88dd,88df,88e5,88e7,88f5,88f7,88fb,892f,89a5,89ad,89b1,89b3,89b5,89b7,89b9,89bb,89c1,89c24,89c2c,89c34,89c3c,89c5,89c7,89c9,89cb,89d1,89d3,89d5,89dd,89e1,89e3,89e5,89e7,89e9,8c2b,8c43,8d09,8e45,8e85,8f4d,8f4f,8f51,8f5d,8f5f,8f63,8f69,8f75,8fa1,8fad,9105,915d,915f,916d,91d5,935b,94cf,9519,95a3,95bd,9663,9689,9aab,a9d5\n"
     ]
    }
   ],
   "source": [
    "# Print tokens for viz (paste into s2.inair.space)\n",
    "print(\",\".join(candidate_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cell mapping to disk\n",
    "TRAIN_CELLS_PATH = Path.home() / \"datasets\" / \"im2gps\" / \"outputs\" / \"s2cell_2007\"\n",
    "\n",
    "mapping = label_mapping.LabelMapping(candidate_tokens)\n",
    "mapping.to_csv(TRAIN_CELLS_PATH / \"cells.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate the target dataset using the above s2 cell tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2997/2997 [00:00<00:00, 10372.90it/s]\n"
     ]
    }
   ],
   "source": [
    "#cell_set = set(candidate_celldicts.keys())\n",
    "mapping = label_mapping.LabelMapping.read_csv(TRAIN_CELLS_PATH / \"cells.csv\")\n",
    "cell_set = set([s2sphere.CellId.from_token(token).id() for token in mapping.name_to_label.keys()])\n",
    "print(len(cell_set))\n",
    "target_df = pandas.read_pickle(TARGET_DF_PATH)\n",
    "\n",
    "s2cell_labels = []\n",
    "for row in tqdm.tqdm(target_df.itertuples(), total=len(target_df.index)):\n",
    "    latlng = s2sphere.LatLng.from_degrees(row.latitude, row.longitude)\n",
    "    s2_cell_id = s2sphere.CellId.from_lat_lng(latlng)\n",
    "\n",
    "    while s2_cell_id.id() not in cell_set:\n",
    "        if s2_cell_id.level() < MIN_CELL_LEVEL:\n",
    "            break\n",
    "        s2_cell_id = s2_cell_id.parent()\n",
    "\n",
    "    if s2_cell_id.id() not in cell_set:\n",
    "        # This example can't be labeled\n",
    "        s2cell_labels.append(None)\n",
    "    else:\n",
    "        s2cell_labels.append(s2_cell_id.to_token())\n",
    "        assert s2_cell_id.to_token() in mapping.name_to_label\n",
    "\n",
    "target_df[\"s2cell\"] = s2cell_labels\n",
    "target_df.to_pickle(DATASET_OUT_PATH / \"s2_annotated.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
