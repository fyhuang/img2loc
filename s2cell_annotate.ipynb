{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotate a (web)dataset with the S2 cell of each example\n",
    "\n",
    "Create a tree of S2 cells adaptively, making sure each cell doesn't have too many/few examples.\n",
    "\n",
    "Apply the S2 cell tree to a webdataset, labeling each example with the smallest S2 cell in the tree that contains the lat/lng of the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import copy\n",
    "import collections\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas\n",
    "import webdataset\n",
    "import s2sphere\n",
    "\n",
    "import tqdm\n",
    "\n",
    "from mlutil import label_mapping\n",
    "\n",
    "MIN_CELL_LEVEL = 5\n",
    "MAX_CELL_LEVEL = 23\n",
    "\n",
    "IM2GPS_2007_PATH = Path.home() / \"datasets\" / \"im2gps\" / \"outputs\" / \"im2gps_2007.pkl\"\n",
    "SV_WORLD1_PATH = Path.home() / \"datasets\" / \"img2loc\" / \"outputs\" / \"world1\" / \"s3_parameterized.pkl\"\n",
    "IM2GPS_2023_PATH = Path.home() / \"datasets\" / \"im2gps\" / \"outputs\" / \"im2gps_2023.pkl\"\n",
    "\n",
    "train_df = pandas.concat([\n",
    "    pandas.read_pickle(IM2GPS_2007_PATH),\n",
    "    pandas.read_pickle(SV_WORLD1_PATH).head(20000),\n",
    "    pandas.read_pickle(IM2GPS_2023_PATH),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse the train dataset to build the S2 cell tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1668402 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1668402/1668402 [00:25<00:00, 64630.74it/s]\n"
     ]
    }
   ],
   "source": [
    "# Format: {level: {cell_id: (child_cell_id, ...)}}\n",
    "cells_by_level = collections.defaultdict(lambda: collections.defaultdict(set))\n",
    "\n",
    "# Build the cell_by_id index and initialize cells_by_level\n",
    "for row in tqdm.tqdm(train_df.itertuples(), total=len(train_df.index)):\n",
    "    latlng = s2sphere.LatLng.from_degrees(row.latitude, row.longitude)\n",
    "    s2_cell_id = s2sphere.CellId.from_lat_lng(latlng)\n",
    "\n",
    "    parent_cell = s2_cell_id.parent(MIN_CELL_LEVEL)\n",
    "    cells_by_level[parent_cell.level()][parent_cell.id()].add(s2_cell_id.id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Level 1: 0it [00:00, ?it/s]\n",
      "Level 2: 0it [00:00, ?it/s]\n",
      "Level 3: 0it [00:00, ?it/s]\n",
      "Level 4: 0it [00:00, ?it/s]\n",
      "Level 5: 100%|██████████| 1995/1995 [00:00<00:00, 3855.69it/s]\n",
      "Level 6: 100%|██████████| 132/132 [00:00<00:00, 433.00it/s]\n",
      "Level 7: 100%|██████████| 86/86 [00:00<00:00, 394.75it/s]\n",
      "Level 8: 100%|██████████| 52/52 [00:00<00:00, 360.09it/s]\n",
      "Level 9: 100%|██████████| 35/35 [00:00<00:00, 283.71it/s]\n",
      "Level 10: 100%|██████████| 39/39 [00:00<00:00, 476.81it/s]\n",
      "Level 11: 100%|██████████| 32/32 [00:00<00:00, 3256.29it/s]\n",
      "Level 12: 100%|██████████| 4/4 [00:00<00:00, 118987.35it/s]\n",
      "Level 13: 0it [00:00, ?it/s]\n",
      "Level 14: 0it [00:00, ?it/s]\n",
      "Level 15: 0it [00:00, ?it/s]\n",
      "Level 16: 0it [00:00, ?it/s]\n",
      "Level 17: 0it [00:00, ?it/s]\n",
      "Level 18: 0it [00:00, ?it/s]\n",
      "Level 19: 0it [00:00, ?it/s]\n",
      "Level 20: 0it [00:00, ?it/s]\n",
      "Level 21: 0it [00:00, ?it/s]\n",
      "Level 22: 0it [00:00, ?it/s]\n",
      "Level 23: 0it [00:00, ?it/s]\n",
      "Level 22: 0it [00:00, ?it/s]\n",
      "Level 21: 0it [00:00, ?it/s]\n",
      "Level 20: 0it [00:00, ?it/s]\n",
      "Level 19: 0it [00:00, ?it/s]\n",
      "Level 18: 0it [00:00, ?it/s]\n",
      "Level 17: 0it [00:00, ?it/s]\n",
      "Level 16: 0it [00:00, ?it/s]\n",
      "Level 15: 0it [00:00, ?it/s]\n",
      "Level 14: 0it [00:00, ?it/s]\n",
      "Level 13: 0it [00:00, ?it/s]\n",
      "Level 12: 100%|██████████| 4/4 [00:00<00:00, 86037.01it/s]\n",
      "Level 11: 100%|██████████| 32/32 [00:00<00:00, 278460.02it/s]\n",
      "Level 10: 100%|██████████| 39/39 [00:00<00:00, 1016011.53it/s]\n",
      "Level 9: 100%|██████████| 35/35 [00:00<00:00, 760625.08it/s]\n",
      "Level 8: 100%|██████████| 52/52 [00:00<00:00, 1306010.83it/s]\n",
      "Level 7: 100%|██████████| 86/86 [00:00<00:00, 2026461.48it/s]\n",
      "Level 6: 100%|██████████| 132/132 [00:00<00:00, 2528073.64it/s]\n",
      "Level 5: 100%|██████████| 1995/1995 [00:00<00:00, 3449149.41it/s]\n",
      "Level 4: 0it [00:00, ?it/s]\n",
      "Level 3: 0it [00:00, ?it/s]\n",
      "Level 2: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cells = 930\n",
      "            cell_id         count\n",
      "count  9.300000e+02    930.000000\n",
      "mean   6.013823e+18   1875.522581\n",
      "std    3.161695e+18   3495.953480\n",
      "min    4.391010e+16    100.000000\n",
      "25%    4.073506e+18    242.250000\n",
      "50%    5.220657e+18    551.500000\n",
      "75%    9.669791e+18   1888.750000\n",
      "max    1.374836e+19  41297.000000\n"
     ]
    }
   ],
   "source": [
    "CELL_MAX_EXAMPLES = 5000\n",
    "CELL_MIN_EXAMPLES = 100\n",
    "\n",
    "def split_tree_leaves_only(input_cells_by_level):\n",
    "    cells_by_level = copy.deepcopy(input_cells_by_level)\n",
    "\n",
    "    # Walk the tree and split cells\n",
    "    for level in range(1, MAX_CELL_LEVEL):\n",
    "        celldict = cells_by_level[level]\n",
    "        for cell_id, cellset in tqdm.tqdm(celldict.items(), desc=f\"Level {level}\"):\n",
    "            if len(cellset) <= CELL_MAX_EXAMPLES:\n",
    "                continue\n",
    "\n",
    "            next_level = level+1\n",
    "            for child_id in cellset:\n",
    "                child_cell = s2sphere.CellId(child_id)\n",
    "                next_level_parent = child_cell.parent(next_level)\n",
    "                cells_by_level[next_level][next_level_parent.id()].add(child_id)\n",
    "            cellset.clear()\n",
    "\n",
    "    # Flatten the cells_by_level dict and remove cells with too few examples\n",
    "    candidate_celldicts = {}\n",
    "    for level, celldict in cells_by_level.items():\n",
    "        for cell_id, cellset in celldict.items():\n",
    "            if len(cellset) >= CELL_MIN_EXAMPLES:\n",
    "                candidate_celldicts[cell_id] = cellset\n",
    "\n",
    "    print(f\"Number of cells = {len(candidate_celldicts)}\")\n",
    "    cell_counts = pandas.DataFrame([(cell_id, len(cellset)) for cell_id, cellset in candidate_celldicts.items()], columns=[\"cell_id\", \"count\"])\n",
    "    print(cell_counts.describe())\n",
    "\n",
    "    candidate_tokens = [s2sphere.CellId(cell_id).to_token() for cell_id in sorted(candidate_celldicts.keys())]\n",
    "    return candidate_tokens\n",
    "\n",
    "def split_tree_keep_parents(input_cells_by_level):\n",
    "    cells_by_level = copy.deepcopy(input_cells_by_level)\n",
    "\n",
    "    # Walk the tree and split cells, keeping cells in the parent cell\n",
    "    for level in range(1, MAX_CELL_LEVEL):\n",
    "        celldict = cells_by_level[level]\n",
    "        for cell_id, cellset in tqdm.tqdm(celldict.items(), desc=f\"Level {level}\"):\n",
    "            if len(cellset) <= CELL_MAX_EXAMPLES:\n",
    "                continue\n",
    "\n",
    "            next_level = level+1\n",
    "            for child_id in cellset:\n",
    "                child_cell = s2sphere.CellId(child_id)\n",
    "                next_level_parent = child_cell.parent(next_level)\n",
    "                cells_by_level[next_level][next_level_parent.id()].add(child_id)\n",
    "\n",
    "    # Starting from bottom, remove cells with too few examples\n",
    "    for level in range(MAX_CELL_LEVEL, 1, -1):\n",
    "        cell_items = list(cells_by_level[level].items())\n",
    "        for cell_id, cellset in tqdm.tqdm(cell_items, desc=f\"Level {level}\"):\n",
    "            if len(cellset) < CELL_MIN_EXAMPLES:\n",
    "                del cells_by_level[level][cell_id]\n",
    "\n",
    "    # Flatten without filtering\n",
    "    candidate_celldicts = {}\n",
    "    for level, celldict in cells_by_level.items():\n",
    "        for cell_id, cellset in celldict.items():\n",
    "            candidate_celldicts[cell_id] = cellset\n",
    "\n",
    "    print(f\"Number of cells = {len(candidate_celldicts)}\")\n",
    "    cell_counts = pandas.DataFrame([(cell_id, len(cellset)) for cell_id, cellset in candidate_celldicts.items()], columns=[\"cell_id\", \"count\"])\n",
    "    print(cell_counts.describe())\n",
    "\n",
    "    candidate_tokens = [s2sphere.CellId(cell_id).to_token() for cell_id in sorted(candidate_celldicts.keys())]\n",
    "    return candidate_tokens\n",
    "\n",
    "\n",
    "#candidate_tokens = split_tree_leaves_only(cells_by_level)\n",
    "candidate_tokens = split_tree_keep_parents(cells_by_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "009c,00a4,0714,07ac,094c,0b44,0c3c,0c44,0c4c,0c64,0c6c,0d04,0d0c,0d14,0d19,0d1b,0d1c,0d1f,0d24,0d2c,0d34,0d3c,0d41,0d424,0d43,0d434,0d44,0d45,0d47,0d4c,0d54,0d5c,0d64,0d6c,0d74,0d7c,0d94,0d9c,0da4,0dac,0db4,0dbc,0e84,0e94,0ec4,0fdc,103c,1254,1294,129c,12a1,12a3,12a4,12a44,12a49,12a4a24,12a4a2c,12a4a3,12a4a34,12a4a3c,12a4a4,12a4b,12a4bc,12a4c,12a4f,12a5,12a54,12a5c,12a7,12ac,12b4,12bc,12c9,12cb,12cc,12cd,12cf,12d4,12dc,12e4,12fc,1304,130c,1314,131c,1324,1329,132b,132c,132d,132f,1334,133c,1344,134c,1354,135c,1364,13ac,1434,144c,1454,145c,1494,149c,14a4,14ac,14b4,14bc,14c4,14cc,14d4,14dc,14e4,14f4,1504,1514,151c,1524,152c,1534,1554,155c,15a4,15c4,1764,1774,177c,1814,1824,182c,1834,183c,1844,185c,18dc,194c,1954,195c,1964,19c4,19cc,19dc,1a4c,1b8c,1b94,1b9c,1ba4,1bf4,1c0c,1c14,1c3c,1c6c,1c74,1dcc,1dd4,1e64,1e7c,1e94,1ebc,1ec4,1ee4,1eec,1ef4,1f64,21dc,21e4,21f4,2214,2a34,2dd4,2ddc,2e44,2e6c,2e7c,302c,3034,304c,3054,30c4,30cc,30d4,30dc,30e4,30fc,3104,310c,3114,311c,3124,312c,3134,313c,3144,314c,3174,31a4,31b4,31cc,31d4,31dc,323c,32fc,3394,33a4,33ac,33bc,3404,3442b,3442c,3443,3444,345c,3464,346c,34e4,3514,353c,3544,3554,355c,356c,357c,35b4,35f4,3664,3694,36a4,36cc,36ec,3724,3754,3884,3894,389c,38ac,38b4,38bc,38dc,38e4,38ec,3904,390c,391c,3944,395c,3964,396c,3974,398c,3994,39e4,39ec,39fc,3a04,3a54,3ae4,3afc,3b04,3b0c,3b3c,3ba4,3bac,3bb4,3bbc,3bc4,3bcc,3bdc,3be4,3db4,3e2c,3e44,3e4c,3e5c,3e94,3ef4,3f4c,3f54,3f6c,3f8c,3fbc,3fcc,400c,4014,4034,403c,4044,405c,4064,406c,40a4,40ac,40b4,40d4,414c,41dc,442c,45c4,45cc,45d4,45dc,4614,463c,4644,464c,4654,465c,4664,466c,4674,467c,4684,468c,4694,469c,46b4,46c4,46dc,46e4,46ec,46f4,46fc,4704,470c,4714,471c,4724,4734,473c,4744,474c,4754,475c,4764,4769,476b,476c,476d,476f,4774,4779,477b,477c,477d,477f,4781,4783,4784,4785,4787,4789,478b,478c,478d,478f,4791,4793,4794,4795,4797,4799,479b,479c,479d,479f,47a4,47a83,47a84,47a844,47a84c,47a85,47a8504,47a850c,47a851,47a8514,47a851c,47a853,47a854,47a857,47a85c,47a8c,47a9,47a9c,47ab,47ac,47ad,47af,47b4,47bc,47c1,47c24,47c2c,47c3,47c34,47c3c,47c3c24,47c3c3,47c3c34,47c3c3c,47c3c4,47c3c5,47c3d,47c3d4,47c3dc,47c3f,47c4,47c5,47c64,47c6c,47c7,47c74,47c7c,47cc,47d4,47d84,47d8c,47d9,47d94,47d9c,47db,47dc,47dd,47df,47e1,47e3,47e4,47e5,47e61,47e64,47e664,47e66c,47e66d,47e66e4,47e66f,47e66fc,47e67,47e674,47e67c,47e6c,47e7,47ec,47f4,47fc,4804,480c,4814,4844,484c,485c,4861,4863,4864,4865,4867,4869,486b,486c,486d,486f,48704,4870c,4871,48714,4871c,4873,4874,4875,487601,487603,487604,4876044,487604b,487604c,487604d,487604f,487605,4876054,487605c,487607,48760c,48761,487614,487619,48761b,48761c,48761d,48763,48764,48765,48767,4876c,4877,48774,4877c,4879,487a4,487ac,487b,487b4,487bc,487c,487d,487f,4881,4884,4885,48864,4886c,4887,48874,4887b,4887c,4887d,4889,488b,488c,488d,488f,4894,489c,48bc,48cc,48d4,492c,4b0c,4b5c,4cac,4cb4,4cbc,4cc9,4ccb,4ccc,4ccd,4ccf,4cd4,4d2c,4d34,4d4c,4d54,4d5c,4f2c,5134,52a4,52ac,52b4,52bc,52c4,52cc,52dc,5324,5334,5344,534c,5354,535c,5364,536c,5374,537c,53a4,5404,540c,5414,547c,5484,548c,54901,54903,54904,54905,54907,5490c,5491,54914,5491c,5493,5494,5495,5497,549c,54a4,54ac,54bc,54c4,54cc,54d4,54ec,56ac,56c4,56cc,56ec,5d94,5f0c,5f74,5f84,5f8c,5f9c,5ff4,5ffc,6004,60184,601884,601889,60188b,60188c,60188d,60188f,60189,601894,6018c,6018f,6019,60194,6019c,601b,601c,601d,601f,6024,671c,697c,6ab4,6ad4,6b0c,6b14,6b1c,6b24,6b74,6b94,6b9c,6ba4,6d0c,6d2c,6d34,6d3c,6d44,6d6c,6d74,6e14,71a4,769c,7954,7c04,7eac,8081,8084,80844,8085,80854,8085804,808580c,808581,8085814,808584,808585,808587,80859,808594,80859c,8085b,8085c,8085d,808c,808d,808e4,808f,808f4,808fc,8094,809c,80a4,80ac,80b4,80bc,80c1,80c2c,80c3,80c34,80c4,80c5,80c7,80cc,80d4,80dc,80ec,8424,842c,858c,85bc,85c4,85cc,85d4,85ec,85f4,85fc,8624,862c,8634,863c,8644,864c,8654,865c,8664,866c,8684,869c,86ac,86bc,86d4,86dc,86e4,86ec,86f4,86fc,8704,870c,8714,871c,8724,872c,8734,873c,8744,874c,8754,875c,8764,876c,8774,877c,8784,878c,8794,879c,87a4,87ac,87b4,87bc,87c4,87cc,87d4,87dc,87e4,87ec,87f4,87fc,8804,8809,880b,880c,880d,880e3,880e4,880e5,880ec,880f,880f4,880fc,8814,881c,8824,882b,882b4,882c,882d,882f,8834,883c,8844,884c,8854,885c,8864,886c,8874,887c,8884,888c,8894,889c,88c4,88cc,88d4,88d9,88db,88dc,88dd,88df,88e4,88ec,88f4,88fc,8904,8924,892c,8934,894c,89a4,89ac,89b1,89b3,89b4,89b5,89b64,89b6c,89b7,89b7ac,89b7b,89b7b1,89b7b3,89b7b4,89b7b64,89b7b6c,89b7b7,89b7b74,89b7b7c,89b7bc,89b7c,89b7d,89b7f,89bc,89c1,89c23,89c24,89c244,89c24c,89c25,89c254,89c2584,89c258c,89c259,89c2594,89c259c,89c25b,89c25c,89c25f,89c27,89c2c,89c3,89c34,89c3c,89c4,89c5,89c7,89cc,89d4,89dc,89e1,89e24,89e2c,89e3,89e34,89e3c,89e4,89e5,89e7,89ec,89fc,8a2c,8c04,8c14,8c2c,8c44,8d0c,8d14,8e2c,8e34,8e3c,8e44,8e64,8e84,8eac,8eb4,8edc,8ef4,8f4c,8f54,8f5c,8f64,8f6c,8f74,8f9c,8fa4,8fac,9004,902c,9104,9114,9144,915c,916c,91ac,91d4,935c,93fc,947c,94cc,94dc,94f4,951c,9524,959c,95a4,95b4,95bc,9614,961c,9664,966c,967c,9684,968c,96ac,9944,9aac,a82c,a9d4,aa6c,bc4c,bc74,bc7c,bd94,bda4,bdac,bdb4,bdbc,bdd4,be84,becc\n"
     ]
    }
   ],
   "source": [
    "# Print tokens for viz (paste into s2.inair.space)\n",
    "print(\",\".join(candidate_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cell mapping to disk\n",
    "cell_mapping_path = \\\n",
    "    Path.home() / \"datasets\" / \"im2gps\" / \"outputs\" / \"s2cell_930_ml.csv\"\n",
    "\n",
    "mapping = label_mapping.LabelMapping(candidate_tokens)\n",
    "mapping.to_csv(cell_mapping_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate the target dataset using the above s2 cell tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2997/2997 [00:00<00:00, 10372.90it/s]\n"
     ]
    }
   ],
   "source": [
    "#cell_set = set(candidate_celldicts.keys())\n",
    "mapping = label_mapping.LabelMapping.read_csv(TRAIN_CELLS_PATH / \"cells.csv\")\n",
    "cell_set = set([s2sphere.CellId.from_token(token).id() for token in mapping.name_to_label.keys()])\n",
    "print(len(cell_set))\n",
    "target_df = pandas.read_pickle(TARGET_DF_PATH)\n",
    "\n",
    "s2cell_labels = []\n",
    "for row in tqdm.tqdm(target_df.itertuples(), total=len(target_df.index)):\n",
    "    latlng = s2sphere.LatLng.from_degrees(row.latitude, row.longitude)\n",
    "    s2_cell_id = s2sphere.CellId.from_lat_lng(latlng)\n",
    "\n",
    "    while s2_cell_id.id() not in cell_set:\n",
    "        if s2_cell_id.level() < MIN_CELL_LEVEL:\n",
    "            break\n",
    "        s2_cell_id = s2_cell_id.parent()\n",
    "\n",
    "    if s2_cell_id.id() not in cell_set:\n",
    "        # This example can't be labeled\n",
    "        s2cell_labels.append(None)\n",
    "    else:\n",
    "        s2cell_labels.append(s2_cell_id.to_token())\n",
    "        assert s2_cell_id.to_token() in mapping.name_to_label\n",
    "\n",
    "target_df[\"s2cell\"] = s2cell_labels\n",
    "target_df.to_pickle(DATASET_OUT_PATH / \"s2_annotated.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
