{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, lr: [0.01]\n",
      "Step 1, lr: [0.10899999999999999]\n",
      "Step 2, lr: [0.20799999999999996]\n",
      "Step 3, lr: [0.30699999999999994]\n",
      "Step 4, lr: [0.40599999999999997]\n",
      "Step 5, lr: [0.505]\n",
      "Step 6, lr: [0.604]\n",
      "Step 7, lr: [0.703]\n",
      "Step 8, lr: [0.8019999999999999]\n",
      "Step 9, lr: [0.9009999999999999]\n",
      "Step 10, lr: [1.0]\n",
      "Step 11, lr: [0.9990133652007716]\n",
      "Step 12, lr: [0.9960573545998883]\n",
      "Step 13, lr: [0.9911436342207189]\n",
      "Step 14, lr: [0.9842915962727349]\n",
      "Step 15, lr: [0.9755282826193186]\n",
      "Step 16, lr: [0.9648882780558826]\n",
      "Step 17, lr: [0.9524135738194835]\n",
      "Step 18, lr: [0.9381534018685916]\n",
      "Step 19, lr: [0.9221640405870447]\n",
      "Step 20, lr: [0.9045085926789764]\n",
      "Step 21, lr: [0.8852567361312731]\n",
      "Step 22, lr: [0.8644844492263919]\n",
      "Step 23, lr: [0.8422737106907913]\n",
      "Step 24, lr: [0.8187121761623498]\n",
      "Step 25, lr: [0.7938928322536104]\n",
      "Step 26, lr: [0.7679136295761007]\n",
      "Step 27, lr: [0.7408770961740204]\n",
      "Step 28, lr: [0.7128899328928904]\n",
      "Step 29, lr: [0.6840625922800625]\n",
      "Step 30, lr: [0.6545088426789764]\n",
      "Step 31, lr: [0.6243453192374836]\n",
      "Step 32, lr: [0.5936910636022049]\n",
      "Step 33, lr: [0.5626670541155353]\n",
      "Step 34, lr: [0.5313957283693969]\n",
      "Step 35, lr: [0.5000004999999998]\n",
      "Step 36, lr: [0.46860527163060295]\n",
      "Step 37, lr: [0.43733394588446456]\n",
      "Step 38, lr: [0.4063099363977949]\n",
      "Step 39, lr: [0.3756556807625161]\n",
      "Step 40, lr: [0.34549215732102356]\n",
      "Step 41, lr: [0.3159384077199374]\n",
      "Step 42, lr: [0.2871110671071094]\n",
      "Step 43, lr: [0.2591239038259793]\n",
      "Step 44, lr: [0.23208737042389901]\n",
      "Step 45, lr: [0.2061081677463896]\n",
      "Step 46, lr: [0.18128882383764996]\n",
      "Step 47, lr: [0.15772728930920857]\n",
      "Step 48, lr: [0.13551655077360802]\n",
      "Step 49, lr: [0.1147442638687268]\n",
      "Step 50, lr: [0.0954924073210235]\n",
      "Step 51, lr: [0.07783695941295532]\n",
      "Step 52, lr: [0.06184759813140823]\n",
      "Step 53, lr: [0.047587426180516555]\n",
      "Step 54, lr: [0.03511272194411727]\n",
      "Step 55, lr: [0.02447271738068138]\n",
      "Step 56, lr: [0.01570940372726508]\n",
      "Step 57, lr: [0.008857365779281]\n",
      "Step 58, lr: [0.0039436454001117735]\n",
      "Step 59, lr: [0.0009876347992284343]\n",
      "Step 60, lr: [1e-06]\n",
      "Step 61, lr: [1e-06]\n",
      "Step 62, lr: [1e-06]\n",
      "Step 63, lr: [1e-06]\n",
      "Step 64, lr: [1e-06]\n",
      "Step 65, lr: [1e-06]\n",
      "Step 66, lr: [1e-06]\n",
      "Step 67, lr: [1e-06]\n",
      "Step 68, lr: [1e-06]\n",
      "Step 69, lr: [1e-06]\n",
      "Step 70, lr: [1e-06]\n",
      "Step 71, lr: [1e-06]\n",
      "Step 72, lr: [1e-06]\n",
      "Step 73, lr: [1e-06]\n",
      "Step 74, lr: [1e-06]\n",
      "Step 75, lr: [1e-06]\n",
      "Step 76, lr: [1e-06]\n",
      "Step 77, lr: [1e-06]\n",
      "Step 78, lr: [1e-06]\n",
      "Step 79, lr: [1e-06]\n",
      "Step 80, lr: [1e-06]\n",
      "Step 81, lr: [1e-06]\n",
      "Step 82, lr: [1e-06]\n",
      "Step 83, lr: [1e-06]\n",
      "Step 84, lr: [1e-06]\n",
      "Step 85, lr: [1e-06]\n",
      "Step 86, lr: [1e-06]\n",
      "Step 87, lr: [1e-06]\n",
      "Step 88, lr: [1e-06]\n",
      "Step 89, lr: [1e-06]\n",
      "Step 90, lr: [1e-06]\n",
      "Step 91, lr: [1e-06]\n",
      "Step 92, lr: [1e-06]\n",
      "Step 93, lr: [1e-06]\n",
      "Step 94, lr: [1e-06]\n",
      "Step 95, lr: [1e-06]\n",
      "Step 96, lr: [1e-06]\n",
      "Step 97, lr: [1e-06]\n",
      "Step 98, lr: [1e-06]\n",
      "Step 99, lr: [1e-06]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fyhuang/dev/mlenv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "/home/fyhuang/dev/mlenv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "param = torch.nn.Parameter(torch.randn(10, 10))\n",
    "\n",
    "optimizer = optim.AdamW(\n",
    "    [param],\n",
    "    lr=1.0,\n",
    "    #weight_decay=0.05,\n",
    "    weight_decay=1e-8,\n",
    ")\n",
    "\n",
    "scheduler = optim.lr_scheduler.SequentialLR(\n",
    "    optimizer,\n",
    "    schedulers=[\n",
    "        optim.lr_scheduler.LinearLR(optimizer, start_factor=0.01, end_factor=1.0, total_iters=10),\n",
    "        optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, eta_min=1e-6),\n",
    "        optim.lr_scheduler.ConstantLR(optimizer, factor=1e-6, total_iters=float('inf')),\n",
    "    ],\n",
    "    milestones=[10, 60],\n",
    ")\n",
    "\n",
    "for i in range(100):\n",
    "    lr = scheduler.get_last_lr()\n",
    "    print(f\"Step {i}, lr: {lr}\")\n",
    "    scheduler.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
